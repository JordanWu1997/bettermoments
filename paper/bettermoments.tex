\documentclass[rnaas]{aastex62}

\pdfoutput=1

\usepackage{lmodern}
\usepackage{microtype}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{multirow}
\usepackage{graphicx}
\bibliographystyle{aasjournal}

% ------------------ %
% end of AASTeX mods %
% ------------------ %

% Projects:
\newcommand{\project}[1]{\textsf{#1}}
\newcommand{\kepler}{\project{Kepler}}
\newcommand{\ktwo}{\project{K2}}

% references to text content
\newcommand{\documentname}{\textsl{Note}}
\newcommand{\figureref}[1]{\ref{fig:#1}}
\newcommand{\Figure}[1]{Figure~\figureref{#1}}
\newcommand{\figurelabel}[1]{\label{fig:#1}}
\renewcommand{\eqref}[1]{\ref{eq:#1}}
\newcommand{\Eq}[1]{Equation~(\eqref{#1})}
\newcommand{\eq}[1]{\Eq{#1}}
\newcommand{\eqalt}[1]{Equation~\eqref{#1}}
\newcommand{\eqlabel}[1]{\label{eq:#1}}

% TODOs
\newcommand{\todo}[3]{{\color{#2}\emph{#1}: #3}}
\newcommand{\dfmtodo}[1]{\todo{DFM}{red}{#1}}
\newcommand{\alltodo}[1]{\todo{TEAM}{red}{#1}}
\newcommand{\citeme}{{\color{red}(citation needed)}}

% math
\newcommand{\T}{\ensuremath{\mathrm{T}}}
\newcommand{\dd}{\ensuremath{ \mathrm{d}}}
\newcommand{\unit}[1]{{\ensuremath{ \mathrm{#1}}}}
\newcommand{\bvec}[1]{{\ensuremath{\boldsymbol{#1}}}}
\newcommand{\Gaussian}[3]{\ensuremath{\frac{1}{|2\pi #2|^\frac{1}{2}}
            \exp\left[ -\frac{1}{2}#1^\top #2^{-1} #1 \right]}}

% VECTORS AND MATRICES USED IN THIS PAPER
\newcommand{\Normal}{\ensuremath{\mathcal{N}}}
\newcommand{\mA}{\ensuremath{\bvec{A}}}
\newcommand{\mC}{\ensuremath{\bvec{C}}}
\newcommand{\mS}{\ensuremath{\bvec{\Sigma}}}
\newcommand{\mL}{\ensuremath{\bvec{\Lambda}}}
\newcommand{\vw}{\ensuremath{\bvec{w}}}
\newcommand{\vy}{\ensuremath{\bvec{y}}}
\newcommand{\vt}{\ensuremath{\bvec{\theta}}}
\newcommand{\vm}{\ensuremath{\bvec{\mu}(\bvec{\theta})}}
\newcommand{\vre}{\ensuremath{\bvec{r}}}
\newcommand{\vh}{\ensuremath{\bvec{h}}}
\newcommand{\vk}{\ensuremath{\bvec{k}}}

% typography obsessions
\setlength{\parindent}{3.0ex}

\begin{document}\raggedbottom\sloppy\sloppypar\frenchspacing

\title{%
Robust moment maps for ALMA observations
}

\author[0000-0003-1534-5186]{Richard Teague}
\affil{University of Michigan, Ann Arbor, MI}

\author[0000-0002-9328-5652]{Daniel Foreman-Mackey}
\affil{Flatiron Institute, New York, NY}

%\keywords{%
%methods: data analysis ---
%methods: statistical
%}

\section{Introduction}

% > Kinematics used to trace planet-disk interaction (and other star stuff).
% > Moment maps require sigma-clipping or masking to get good values. Bad!
% > No real uncertainties for the values.
% > Intensity weighted values also confused by far side of the disk (make the disk look flat).
% > Can fit a Gaussian, but slow and assumes an implicit line profile (not true for optically thick lines due to core saturation and seeing the back side of the disk).
% > Centroid fitting better.

Using the kinematics of gas within a protoplanetary disk, particularly detecting deviation from Keplerian rotation, has been shown to be a promising method for inferring planet-disk interactions (Perez 2015, 2018, Teague 2018, Pinte 2018). For such studies a reliable velocity profile must be extracted from the datacube.

Typically (line-of-sight) velocity maps, more commonly called `first moment maps', are made by taking the intensity-weighted velocity at each pixel (equation?). The resulting value is very sensitive to the noise in the spectrum and, particularly in the case where near and far sides of the disk are resolved, biased by non-symmetric line profiles. An alternative is to use the velocity coordinate of the maximum intensity at each pixel (called the `ninth moment' if generated using \texttt{CASA}). While insensitive to emission arising from the far side of the disk, the precision of this method is limited by the spectral resolution of the data.

As noise affects both these methods, sigma-clipping and masking (using some Keplerian profile) are typically used to improve the fidelity, however make strong assumptions about the emission morphology

Furthermore

An alternative approach can be made to fit an analytical line profile to the data and extract the line centre. This however makes the implicity

This research note. \citep{Perez:2018}

\section{Technical details}

It has been demonstrated that fitting a quadratic surface to astronomical
imaging can produce near-optimal estimates of source centroids
\citep{Vakili:2016}.
Here we apply this method to estimate the velocity centroid in each pixel
non-parametrically.
This method has the benefit of being less sensitive to the shape of the wings
of the line spread function than standard moment estimation methods.
Unlike the `ninth moment' method, our quadratic method achieves sub-pixel
precision in the velocity estimates.

The fundamental idea upon which this method is built is that we can fit a
quadratic model to the intensity values surrounding the maximum pixel and
analytically maximize that function to find the velocity estimate.
Following \citet{Vakili:2016}, we find the pixel of maximum intensity in the
spectrum and extract that pixel value $f_0$ and the one to the left $f_-$ and
right $f_+$.
Modeling these three intensities as a quadratic
\begin{eqnarray}
f(x) &=& a_0 + a_1\,(x-x_0) + a_2\,{(x-x_0)}^2
\eqlabel{quad}
\end{eqnarray}
where $x_0$ is the pixel coordinate of maximum intensity and $x$ is in units
of pixels, we find
\begin{eqnarray}
a_0 &=& f_0 \\
a_1 &=& \frac{1}{2}(f_+ - f_-) \\
a_2 &=& \frac{1}{2}(f_+ + f_- - 2\,f_0) \quad.
\end{eqnarray}
By maximizing \Eq{quad}, we find the following estimate for the pixel
coordinate of maximum velocity:
\begin{eqnarray}
x_\mathrm{max} &=& x_0 - \frac{a_1}{2\,a_2} \\
    &=& x_0 - \frac{f_+ - f_-}{2\,(f_+ + f_- - 2\,f_0)} \quad.
\end{eqnarray}

We can also estimate the statistical uncertainty on $x_\mathrm{max}$ by
propagating the uncertainty from the fluxes to uncertainties on the polynomial
coefficients.
If we assume independent Gaussian uncertainties on the fluxes with standard
deviation $\sigma$, the covariance matrix for the polynomial coefficients
$\bvec{a} = {(a_2,\,a_1,\,a_0)}^\T$ is
\begin{eqnarray}
\Sigma_\bvec{a} = \sigma^2\,\left(\begin{array}{ccc}
\frac{3}{2} \quad & \quad 0 \quad &\quad 1 \\
0\quad &\quad \frac{1}{2}\quad &\quad 0 \\
-1\quad &\quad 0\quad &\quad 1
\end{array}\right)\quad.
\end{eqnarray}
Using these values and linearized propagation of uncertainty, we find the
following approximation for the \emph{statistical} uncertainty on
$x_\mathrm{max}$
\begin{eqnarray}
{\sigma_{x_\mathrm{max}}}^2 = \frac{\sigma^2}{8}\,\left[
    \frac{3}{{a_2}^2} + \frac{{a_1}^2}{{a_2}^4}
\right]\quad.
\end{eqnarray}
We emphasize that there are other sources of systematic uncertainty that must
be considered in production.



\bibliography{bettermoments}

%\begin{figure}[htbp]
%\begin{center}
%\includegraphics[width=0.8\textwidth]{figure.pdf}
%\caption{%
%    The empirical computational scaling of the algorithms.
%    \emph{(top row)}: The cost of computing \eq{loglike} as a
%    function of the number of data points ($N$; left) and the model complexity
%    ($J$; right).
%    \emph{(bottom row)}: The cost of computing the gradient of \eq{loglike}
%    with respect to the vector $\bvec{a}$ and the matrices $U$, $V$, and $P$.
%    In the left panels, each line corresponds to a different value of $J$ as
%    indicated in the legend (with $J$ increasing from bottom to top).
%    Similarly, in the right panels, the lines correspond to different values
%    of $N$ increasing from bottom to top.
%    In both cases, the theoretical scaling is $\mathcal{O}(N,J^2)$.
%\figurelabel{figure}}
%\end{center}
%\end{figure}


\end{document}
